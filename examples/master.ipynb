{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acCb-woRH3aE"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nlsa6MB8H3aF"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "sys.path.append('..')\n",
    "import phe as pallier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu processor\n"
     ]
    }
   ],
   "source": [
    "proc = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {proc} processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VydsghFtH3aF"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XmCsiS6zH3aF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c77d82870204ad0b85e37bdd32f74a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            self.conv_block(3, 32),\n",
    "            self.conv_block(32, 32),\n",
    "            self.conv_block(32, 64, stride=2),\n",
    "            self.conv_block(64, 64),\n",
    "            self.conv_block(64, 64),\n",
    "            self.conv_block(64, 128, stride=2),\n",
    "            self.conv_block(128, 128),\n",
    "            self.conv_block(128, 256),\n",
    "            self.conv_block(256, 256),\n",
    "            torch.nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(256, 10)\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.model(x)\n",
    "        B, C, _, _ = h.shape\n",
    "        h = h.view(B, C)\n",
    "        return self.classifier(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUke8SbXH3aG"
   },
   "source": [
    "### Encryption Functions\n",
    "These functions return the encryption and decryption functions used by the local devices to encrypt their weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "12DYw8iLH3aG"
   },
   "outputs": [],
   "source": [
    "def alg_base():\n",
    "    return lambda x:x, lambda x:x\n",
    "\n",
    "def alg_pallier():\n",
    "    public_key, private_key = pallier.generate_paillier_keypair()\n",
    "    return public_key.encrypt, private_key.decrypt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_NdCw9xH3aH"
   },
   "source": [
    "### Merging Functions\n",
    "These functions are used by the central server to get the new global model by merging the local encrypted weight updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0zuWb1eMH3aH"
   },
   "outputs": [],
   "source": [
    "def merge_avg(cipher_weight_dicts):\n",
    "    result = OrderedDict()\n",
    "    # sum the weight tensors\n",
    "    for cipher_weight_dict in cipher_weight_dicts:\n",
    "        for key, tensor in cipher_weight_dict.items():\n",
    "            result[key] = result.get(key, 0) + tensor\n",
    "    # divide the weight tensors to get the average\n",
    "    for key in result.keys():\n",
    "        result[key] = result[key] / len(cipher_weight_dicts)\n",
    "    return result\n",
    "\n",
    "def merge_sum(cipher_weight_dicts):\n",
    "    result = OrderedDict()\n",
    "    # sum the weight tensors\n",
    "    for cipher_weight_dict in cipher_weight_dicts:\n",
    "        for key, tensor in cipher_weight_dict.items():\n",
    "            result[key] = result.get(key, 0) + tensor\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAOSrsvoH3aH"
   },
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3W4A9AJ9H3aH"
   },
   "outputs": [],
   "source": [
    "class Device():\n",
    "    def __init__(self, device_id, trainset, net, epochs, func_alg, data_pct=0.1, bsz=128, lr=0.1):\n",
    "        print(f'\\tInitializing Device {device_id}')\n",
    "        # initialize core device properties\n",
    "        self.id = device_id\n",
    "        \n",
    "        # initialize device dataset\n",
    "        data_idxs = np.random.choice(len(trainset), size=int(data_pct * len(trainset)), replace=False)\n",
    "        self.trainloader = torch.utils.data.DataLoader(trainset, batch_size=bsz, sampler=data_idxs)\n",
    "        \n",
    "        # initialize device net\n",
    "        self.net = net\n",
    "        self.epochs = epochs\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.net.parameters(), lr=lr, momentum=0.9)\n",
    "        milestones = [int(0.25*epochs), int(0.50*epochs), int(0.75*epochs)]\n",
    "        self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=milestones, gamma=0.1)\n",
    "        \n",
    "        # initialize encryption\n",
    "        print(\"Initializing Encryption //\")\n",
    "        start = datetime.now()\n",
    "        self.e, self.d = func_alg()\n",
    "        end = datetime.now()\n",
    "        print(\"Have Keys\")\n",
    "        print((end - start).total_seconds() / 60.0)\n",
    "        \n",
    "        # initialize statistics\n",
    "        \n",
    "    def train(self):\n",
    "        self.net.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss, correct, total = 0, 0, 0\n",
    "            for batch_idx, (inputs, targets) in enumerate(self.trainloader):\n",
    "                inputs, targets = inputs.to(proc), targets.to(proc)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.net(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                predicted = outputs.max(1)[1]\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "                #sys.stdout.write(f'\\r(Device {self.id}/Epoch {epoch}) Train Loss: {total_loss/(batch_idx+1):.3f} | Train Acc: {100.*correct/total:.3f}')\n",
    "                #sys.stdout.flush() \n",
    "        \n",
    "    def test(self):\n",
    "        self.net.eval()\n",
    "        losses, correct, total = [], 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(proc), targets.to(proc)\n",
    "                outputs = self.net(inputs)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                predicted = outputs.max(1)[1]\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "        #sys.stdout.write(f' | Test Loss: {sum(losses)/len(losses):.3f} | Test Acc: {100.*correct/total:.3f}\\n')\n",
    "        #sys.stdout.flush()         \n",
    "                \n",
    "    def transmit(self):\n",
    "        cipher_weights = OrderedDict()\n",
    "        \n",
    "        print(\"Timing encryption of tensor objects\")\n",
    "        start = datetime.now()\n",
    "        for key, tensor in self.net.state_dict().items():\n",
    "            print(\"Tensor Object\", key)\n",
    "            cipher_weights[key] = self.e(tensor)\n",
    "        \n",
    "        print(\"Time to run\")\n",
    "        print((end - start).total_seconds() / 60.0)\n",
    "        return cipher_weights\n",
    "            \n",
    "    def load(self, cipher_weights):\n",
    "        plain_weights = OrderedDict()\n",
    "        \n",
    "        print(\"Timing decryption of tensor objects\")\n",
    "        for key, tensor in cipher_weights.items():\n",
    "            print(\"Tensor Object\", key)\n",
    "            plain_weights[key] = self.d(tensor)\n",
    "        \n",
    "        print(\"Time to run\")\n",
    "        print((end - start).total_seconds() / 60.0)\n",
    "        self.net.load_state_dict(plain_weights)\n",
    "\n",
    "\n",
    "class Server():\n",
    "    def __init__(self, func_merge=merge_avg):\n",
    "        self.func_merge = func_merge\n",
    "        self.weights = OrderedDict()\n",
    "        \n",
    "    def merge(self, cipher_weight_dicts):\n",
    "        self.weights = self.func_merge(cipher_weight_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIP6wlJsH3aI"
   },
   "source": [
    "### Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpCOFlPZH3aI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Server\n",
      "Initializing Devices\n",
      "\tInitializing Device 0\n",
      "Initializing Encryption //\n",
      "Have Keys\n",
      "0.00452965\n",
      "Round 0\n",
      "Timing encryption of tensor objects\n",
      "Tensor Object model.0.0.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.0.1.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.0.1.bias\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.0.1.running_mean\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.0.1.running_var\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.0.1.num_batches_tracked\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.1.0.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.1.1.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.1.1.bias\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.1.1.running_mean\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.1.1.running_var\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.1.1.num_batches_tracked\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.2.0.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.2.1.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.2.1.bias\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.2.1.running_mean\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.2.1.running_var\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.2.1.num_batches_tracked\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.3.0.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.3.1.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.3.1.bias\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.3.1.running_mean\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.3.1.running_var\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.3.1.num_batches_tracked\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.4.0.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.4.1.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.4.1.bias\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.4.1.running_mean\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.4.1.running_var\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.4.1.num_batches_tracked\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n",
      "Tensor Object model.5.0.weight\n",
      "Paillier --> Encrypting Tensor\n",
      "Paillier --> Flattening Tensor\n",
      "Paillier --> Encrypting Array\n"
     ]
    }
   ],
   "source": [
    "def run(num_devices, local_epochs, rounds, round_device_pct, func_alg, func_merge):\n",
    "    print(\"Initializing Server\")\n",
    "    server = Server(func_merge=func_merge)\n",
    "    print(\"Initializing Devices\")\n",
    "    devices = [Device(d_id, trainset, ConvNet().to(proc), local_epochs, func_alg) for d_id in range(num_devices)]\n",
    "\n",
    "    for round_num in range(rounds):\n",
    "        print(f'Round {round_num}')\n",
    "        round_devices = np.random.choice(devices, size=max(int(num_devices * round_device_pct), 1), replace=False).tolist()\n",
    "        for device in round_devices:\n",
    "            device.train()\n",
    "        server.merge([device.transmit() for device in round_devices]) # the state_dict objects this function operates on are all encrypted\n",
    "        for device in devices: # For performance I could instead only load the current global model into the next round's round_devices\n",
    "            device.load(server.weights) # the device decrypts and loads the merged weights\n",
    "            device.optimizer.zero_grad()\n",
    "            device.optimizer.step()\n",
    "            device.scheduler.step()\n",
    "        \n",
    "        devices[0].test()\n",
    "        \n",
    "    return devices[0]\n",
    "\n",
    "start = datetime.now()\n",
    "data_device = run(1, 1, 5, 1, alg_pallier, merge_avg)\n",
    "end = datetime.now()\n",
    "print(\"Time to run\")\n",
    "print((end - start).total_seconds() / 60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Justin Colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
